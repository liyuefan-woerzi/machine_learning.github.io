# CS82 Introduction to Machine Learning
## Week 9 - Training Neural Networks

### Deep Neural Networks 

Deep Neural Networks (DNN) are stacked perceptrons interconnected with intreguate patterns to solve specific tasks.  DNN have the ability to solve much more complicated tasks that are more similar to the type of tasks humans can solve. An MLP classifier can be a DNN given that we have enough hidden layers.

![img](image/1_cuTSPlTq0a_327iTPJyD-Q.png)

While we won't go into detail into any of the architectures above, RNNs, GANs are some networks that are seeing many applications.

### Loss Function

**Loss function** calculates the error in our predictions. There are many Loss functions, most of which are beyond the scope of this class. We could even define our own loss function if we felt ambitious. Defining our own loss function would lead to debatable effects on the training speed and efficiency of our approach. There are some standard loss functions that are commonly used for classification or regression problems. 

The **activation** function calculates the output value of a single perceptron. We can use the sigmoid function, linear, and even define our own function. 

A Neural Network as we saw can be used for both classification and regression problems. We have to pick the correct Loss function and last layer activation function for the problem at hand. The activation functions in the **hidden layers** are not as restricted by the problem we are trying to solve.

### Helpful Table

| Problem Type                             | Last-layer activation | Loss function              | Example                                                      |
| :--------------------------------------- | :-------------------- | :------------------------- | :----------------------------------------------------------- |
| Binary classification                    | sigmoid               | binary_crossentropy        | Dog vs cat, Sentiemnt analysis(pos/neg)                      |
| Multi-class, single-label classification | softmax               | categorical_crossentropy   | MNIST has 10 classes single label (one prediction is one digit) |
| Multi-class, multi-label classification  | sigmoid               | binary_crossentropy        | News tags classification, one blog can have multiple tags    |
| Regression to arbitrary values           | None                  | mse                        | Predict house price(an integer/float point)                  |
| Regression to values between 0 and 1     | sigmoid               | mse or binary_crossentropy | Engine health assessment where 0 is broken, 1 is new         |

### Softmax

**Softmax** is a function that transforms a vector into what can be interperted as a probability distribution. After the transformation, the final vector will have properties such as all of the probabilities add up to 1 and they all have a value between 0 and 1. Higher input values are assigned exponentially larger probabilities.
$$
SoftMax(x)=\frac{e^x}{\sum{e^x}}
$$
The output vector from a softmax function can be interperted as the probability of the input belonging to class $i$ where $i$ is the class index.

**Example**

Assume we have some scores, these scores can be the output from previous perceptrons to the last layer perceptron.

```python
import numpy as np
scores=np.array([34,24,12,39])

def softmax(x):
	return np.exp(x)/np.sum(np.exp(x))

probabilities=softmax(scores)
print("The probability distribution is: %s"%probabilities)
print("The probability sum should up to 1: %f"%probabilities.sum())
print("The index with the highest probability is: %d"%np.argmax(probabilities))
print("The the highest probability is: %f"%np.max(probabilities))



```

>The probability distribution is: [6.69284889e-03 3.03854870e-07 1.86694884e-12 9.93306847e-01]
>
>The probability sum should up to 1: 1.000000
>
>The index with the highest probability is: 3
>
>The the highest probability is: 0.993307

#### Visual Comparison

A neural network with 4 outputs can be used to classify 4 different classes (Multinomial)

![](image/1_DW0Ccmj1hZ0OvSXi7Kz5MQ.jpeg)



Each node outputs a probability of each class. For example 1st output perceptron is the Probability of the input belonging to the first class second output perceptron is probability of class 2 etc.

A Neural network with 1 output can be used for binary classification or for a Regression task 

![](image/1_Gh5PS4R_A5drl5ebd_gNrg@2x.png)



The loss function we use is important, and the reason of why it is important will become more obvious on understanding how we train the weights.

The **weights** in the above example can be visualized as the arrows between the perceptrons. 

### Updating the Weights

Example of an **Update rule**

1. Make a prediction on the training dataset and obtain the output $y_{pred}$
2. Calculate the difference between our $y_{pred}$ and the actual real, **target**  $y_{target}$, we then have $MSE=\frac{(y_{pred}-y_{target})^2}{2}$
3. Perform **Backpropagation**, by differentiating the error function using the chain rule our goal is to calculate the partial derivative of Error with respect to the weights. We write this derivative as $\frac{dError}{dW}$. It signifies the change direction and magnitude of change to error with small changes in the weight vector.
4. Update the new weights using update rule  $W=W_{before}+\text{learning_rate}\times  \frac{dError}{dW}$

For a single Perceptron we only have a single Weights array but for more perceptrons combined together, we have to **propagate** the error from the output layer all the way to the input layer. 

**Notes**

* Learning rate affects how much we consider the error in updating the new weights. 
* The Loss function must be differentiable, which means that the derivative of that function must exist
* For the first iteration, the weights can be randomly initialized or initialized to zero. The best technique is to initialize them to a value close to zero but randomly.
* The first few initial predictions will be completely random.

**Example**

Consider the neural network below, where 

$w$ are the **weights**,

 $i$ is the **input**, 

$h$ is the **hidden layer**

$o$ is the **output layer**

our loss function is $MSE=\frac{(y_{pred}-y_{target})^2}{2}$

![](../image/neural_network-7-20190727105739534.png)

Let's assume we want to update $w_5$. We start by first calculating the total error of our prediction which in this case is the sum of the error from perceptron $o_1$ and $o_2$. 
$$
E_{total}=E_{o_1}+E_{o_2}
$$


![output_1_backprop](../image/output_1_backprop-4.png)

* After a Forward pass the error is calculated as $E_{o_1}=0.27$,  $E_{o_2}=0.024$ and $E_{total}=0.294$

* To update $w_5$ we need to calculate $\frac{dE_{total}}{dw_5}$

* We update $w_5$ as $w_5=w_5-\lambda \times \frac{dE_{total}}{dw_5} $

  

  **In Practice**

  Calculating $\frac{dE_{total}}{dw_5}$
  $$
  \frac{dE_{total}}{dw_5}=\frac{dE_{o_1}}{dw_5}+\frac{dE_{o_2}}{dw_5}
  $$
  $\frac{dE_{o_2}}{dw_5}$ is zero because it is a constant when considered with respect to the changes in $w_5$. That is because there is no $w_5$ in the function of $E_{o_2}$
  $$
  \frac{dE_{total}}{dw_5}=\frac{dE_{o_1}}{dw_5}=\frac{d\frac{(y_{target}-y_{pred})^2}{2}}{dw_5}
  $$
  We know $y_{target}$ is calculated by the linear activation function (because that is what we chose for this example). That means that to make a prediction for that single perpectron and calculate $y_{target}$, we use a linear regression model of the form $y_{pred}=w_5\times h_1+w_6\times h_2+b_2$

  We can replace $y_{target}$ in the above relationship.
  $$
  \frac{d\frac{(y_{target}-y_{pred})^2}{2}}{dw_5}=\frac{d\frac{(y_{target}-w_5\times h_1+w_6\times h_2+b_2)^2}{2}}{dw_5}
  $$
  The derivative is only with respect to $w_5$ so we treat every other variable as a constant. Using the rules of derivation from a previous class or simply an online solver such as [Symbolab](https://www.symbolab.com/solver/partial-derivative-calculator/) we can input in the calculator `\frac{\partial }{\partial \:w_5}\left(\left(\left(y-w_5\cdot \:h_1+w_6\cdot \:h_2\right)^2/2\right)\right)` 

  or visit the link

  ` https://www.symbolab.com/solver/partial-derivative-calculator/%5Cfrac%7B%5Cpartial%20%7D%7B%5Cpartial%20%20w_%7B5%7D%7D%5Cleft(%5Cleft(%5Cleft(y-w_%7B5%7D%5Ccdot%20%20h_%7B1%7D%2Bw_%7B6%7D%5Ccdot%20%20h_%7B2%7D%2Bb_%7B2%7D%5Cright)%5E%7B2%7D%2F2%5Cright)%5Cright)`

  ![image-20190727121233417](../image/image-20190727121233417.png)

  

  the above derivative's result is:
  $$
  \frac{d\frac{(y_{truth}-w_5\times h_1+w_6\times h_2+b_2)^2}{2}}{dw_5}=-h_1\left(y_{truth}-w_5h_1+w_6h_2+b_2\right)
  $$
  To calculate the exact value of the derivative for the update rule for $w_5$ we simply plug in the existing values from our network. Where 

* $h_1$ is the output from the hidden layer perceptron 1

* $w_5$ and $w_6$ are the coefficients for perceptron $o_1$ with bias $b_2$

![neural_network (../image/neural_network-9-20190727121527407.png)](https://matthewmazur.files.wordpress.com/2018/03/neural_network-9.png?w=525)

Assume the above example values for our network and a ground truth value $y_{target}=0$ with a $\text{learning rate} =\lambda=0.01$

$h_1=i\times w+b_1=0.0275+0.35=0.3775$ 

$h_2=i\times w+b_1=0.0425+0.35=0.3925$ 

 we have linear activation function so we take the above values as is (instead of passing them through a sigmoid or another function). $h$ values are the ones we calculate during the forward pass.
$$
w_5=0.4+\lambda \times(-h_1\left(y_{truth}-w_5h_1+w_6h_2+b_2\right))=0.4+0.01\times(-0.3775(0-0.4\times 0.3775+0.45\times0.3925+0.6))=0.39763
$$
We can repeat the same process for the remaining of weights $w_6$, $w_7$ and $w_8$

### Backpropagation Algorithm

Is a technique by which we use the Loss in the final output layer to propagate backwards to update gradually the weights for every single perceptron going backwards.

* We move forward through the neural network **Feedforward**. We use the original input and pass it through the activation function and generate an output for each perceptron. We then pass that output to the perceptrons in the next layer. 
* Once we reach the last perceptron we calculate the Loss.
* We calculate the derivative of the Loss with respect to W 
* We use the gradient, the rate of change from the previous layer to caclulate the rate of change for the weights of the current layer.
* We calculate the partial derivative of the hidden weights using the gradient we calculated for the layers proceeding our current layer
* Once we reach the first layer all of the weights should have been updated.

![nn-calculation](../image/nn-calculation-20190727123138946.png)

**Notes**

* One of the main disadvantage of DNN is that the updates to the weights deeper inside the network will be smaller because the gradient decreases in value as we go deeper and the updates become smaller and smaller. This is called the **vanishing gradient problem** and is the reason that research in Deep Neural Network was delayed for many years.
* **Exploding Gradients**, is the exact opposite, it is when the gradients grow so large that the updates are enormous leading to an untrainable network. 

### Gradient Descent 

**Gradient** or $\nabla$ is the derivative over an entire vector. The derivative of a function is for a single element but if we take the derivative of a function with respect to each element in that vector we have the **Gradient** 

Example:
$$
f(x,y,z)=x+y^2+z^3
\\
\nabla f(x,y,z)=(\frac{df}{dx},\frac{df}{dy},\frac{df}{dz})=(1,2y,3z^2)
$$


If we want to visualize the gradient of a function it tells us where this function increases and where it decreases. The steeper the angle the higher the rate of change of that function. Example of visualization of a Gradient for two variables x and y, the Z is the error we have for each given x,y. 

![Image result for gradient visualization](image/fig5.gif)





The idea behind Gradient Descent is that we start from a random place (random x and y) and we calculate the gradient for each given point. The Gradient will then point us to the direction that the loss is decreasing. All we have to do is use that direction and an amount we can specify to make an update to our weights that will decrease our Loss function even further. 

### Learning Rate 

Learning rate specifies the amount by which we make an update to the weights at each given step. The problem is that we don't want a very high learning rate or very small learning rate. 

* High learning rate - **Will never Learn** will jump over the minimum point
* Low Learning rate - **Will never Learn** will take too small steps to ever reach the minimum point

There are few minimum points, there are 

**Local Minimums** these are minimum points that standout in their surrounding values. 

**Local minimum** these are the points for which there are no smaller values for the entire function. 

Example:

![Image result for local minimum](image/1200px-Extrema_example_original.svg.png)



Our goal is to find the global minimum. For complex problems this global minimum can take hundreds of hours and extreme computing power to find. In simple cases it is easy to find but for more complex problem we usually are never able to find it or ever will. We usually can get stuck in a local minimum. 

Picking the right learning rate, will help us avoid getting stuck in a local minimum or never learn. 

![Image result for learning rate](image/Screen-Shot-2018-02-24-at-11.47.09-AM.png)



### Optimizers

**Optimizers** are methods that define our **update rule**. Instead of picking only the learning rate, and considering the steepness they introduce concepts such as momentum or other hyper parameters that we need to tune to train optimally. 



![Comparison of Adam to Other Optimization Algorithms Training a Multilayer Perceptron](image/Comparison-of-Adam-to-Other-Optimization-Algorithms-Training-a-Multilayer-Perceptron.png)

Comparison of Optimizers



![img](image/contours_evaluation_optimizers.gif)



![img](image/saddle_point_evaluation_optimizers.gif)

### Which Optimizer to Use?

No correct answer. Depends on your function and data. RMSprop and Adam (Momentum) are the most widely used. 

### Overfitting vs Underfitting

**Overfitting** happens very often with Neural Networks. That is because they can have thousand parameters and they can create an exact fit over the training data by tuning them as to reduce the loss close to zero. The problem with overfitting is that the model performs great on training data but fails on test data.

One way to combat that is to split the data into train and test and evaluate the model on test data. This will provide a better accuracy score than evaluating on the train data. 

**Underfitting** is when we are not able to learn an apropriate relationship between the data. This can happen for neural networks mainly because of bad parameters to our model. Bad parameters such as learning rate, number of layers/neurons can create a model that is underfit. 

An underfit model will perform poorly on **both** the training and test data. This is in contrast to an overfit model that will perform great **only** at the training data. A model that is trained properly will perform on both train and test data similarly. 

![Image result for overfitting vs underfitting](../image/1*JZbxrdzabrT33Yl-LrmShw.png)

### Cross-Validation for Classification

For classification Accuracy, simply knowing that we have a 0.99 score can often not be enough. Imagine the scenario that we are classifying if someone has a rare disease or not. If we classified everyone as not having the disease we would get a pretty high accuracy of 0.99. However this is very misleading because we missed 100% of the people with the disease. We use different metrics for that reason. 

For a binary classification problem we have the following definitions

A quick way to understand {Prediction Outcome} {Actual Class}

<figure><table>
<thead>
<tr><th>&nbsp;</th><th colspan=3 style="text-align:center"><span>Predicted Class</span></th></tr></thead>
  <tbody><tr><td></td></td><td>&nbsp;</td><td><span>Yes</span></td><td><span>No</span></td></tr><tr><td  rowspan=2><strong><span>Actual Class</span></strong></td><td><span>Yes</span></td><td><span>True Positive</span></td><td><span>False Positive</span></td></tr><tr><td><span>No</span></td><td><span>False Negative</span></td><td><span>True Negative</span></td></tr></tbody>
</table></figure>
<p>&nbsp;</p>
For **Multiple Classes** we use a **Confusion Matrix** which is an extension of the above 4x4 matrix. 

<figure><table>
<thead>
<tr><th>&nbsp;</th><th colspan=4 style="text-align:center"><span>Predicted Class</span></th></tr></thead>
  <tbody><tr><td></td></td><td>&nbsp;</td><td><span>Class 1</span></td><td>...</td></td><td><span>Class N</span></td></tr><tr><td  rowspan=3><strong><span>Actual Class</span></strong></td><td><span>Class 1</span></td><td><span></span></td><td></td></td><td><span></span></td></tr><tr><td><span>...</span></td><td><span></span></td><td></td></td><td><span></span></td></tr>
<tr><td><span>Class N</span></td><td><span></span></td><td></td></td><td><span></span></td></tr></tbody>
</table></figure>
<p>&nbsp;</p>
We can quickly evaluate a confusion matrix by checking the **diagonal**. This is the cell at location i,i that starts from the top left corner and goes all the way to the bottom right corner. The higher the values in the diagonal and the lower the values in all of the other cells the better our model is performing.

![Image result for confusion matrix](../image/Confusion-matrix-for-multi-class-classification-The-confusion-matrix-of-a.png)

#### Precision

Precision is the ratio of correctly predicted positive observations to the total predicted positive observations. The question that this metric answer is of all passengers that labeled as survived, how many actually survived? High precision relates to the low false positive rate. 
$$
\text{Precision}=\frac{TP}{TP+FP}
$$

```python
from sklearn.metrics import precision_score
precision_score(y_true, y_pred)
```



#### Recall

Recall is the ratio of correctly predicted positive observations to the all observations in actual class - yes. The question recall answers is: Of all the passengers that truly survived, how many did we label? 
$$
\text{Recall}=\frac{TP}{TP+FN}
$$

```
from sklearn.metrics import recall_score
recall_score(y_true, y_pred)
```



#### F1 score

 F1 Score is the weighted average of Precision and Recall. Therefore, this score takes both false positives and false negatives into account. F1 is usually more useful than accuracy, especially if you have an uneven class distribution. It takes a value between 0 and 1
$$
\text{F1 score}=2\times \frac{\text{Recall}\times \text{Precision}}{\text{Recall}+\text{Precision}}
$$

```
from sklearn.metrics import f1_score
f1_score(y_true, y_pred) 
```



### ROC Curve

The ROC curve is a performance measurement for classification problem at various thresholds settings. ROC is a probability curve and AUC represents degree or measure of separability. It tells how much model is capable of distinguishing between classes. Higher the AUC, better the model is at predicting 0s as 0s and 1s as 1s. By analogy, Higher the AUC, better the model is at distinguishing between patients with disease and no disease.

**AUC** is the area under the ROC curve 

![image-20190726145455311](../image/image-20190726145455311.png)

TP Rate is the precision 

FP Rate is defined as
$$
\text{FP Rate}=\frac{FP}{FP+TN}
$$

```python
from sklearn.metrics import roc_auc_score
roc_auc_score(y_true, y_pred) 
```

### Example

For the Iris dataset a confusion matrix can look like the following. We use a library called `seaborn`. If it is not installed you can uncomment the installation line in the following code or run on command line window or seperate cell `pip3 install seaborn`

```python
import numpy as np
import matplotlib.pyplot as plt
%matplotlib inline
# Uncoment to install seaborn
# !pip3 install seaborn
import seaborn as sns
from sklearn import svm, datasets
from sklearn.metrics import confusion_matrix
from sklearn.model_selection import train_test_split
import pandas as pd

iris = datasets.load_iris()
X=iris.data
y=iris.target
class_names = iris.target_names
X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)
clf = svm.SVC(kernel='linear', C=0.01)
y_pred = clf.fit(X_train, y_train).predict(X_test)
# Plot normalized confusion matrix
cm=confusion_matrix(y_test, y_pred)
# Pandas provides a nice plotting functionality
df_cm = pd.DataFrame(cm, index = [i for i in class_names],
                  columns = [i for i in class_names])
                  
sns.heatmap(df_cm)
```



![image-20190726141949565](../image/image-20190726141949565.png)

```python
from sklearn.metrics import precision_score
from sklearn.metrics import f1_score
from sklearn.metrics import recall_score
from sklearn.metrics import roc_auc_score
from sklearn.preprocessing import LabelBinarizer

def multiclass_roc_auc_score(y_test, y_pred, average="macro"):
  lb = LabelBinarizer()
  lb.fit(y_test)
  y_test = lb.transform(y_test)
  y_pred = lb.transform(y_pred)
  return roc_auc_score(y_test, y_pred, average=average)


# we use average weighted for multiclass
print("Precision: %f"%precision_score(y_test, y_pred, average="weighted"))
print("F1 Score: %f"%f1_score(y_test, y_pred,average="weighted"))
print("Recall: %f"%recall_score(y_test, y_pred,average="weighted"))
print("ROC AUC: %f"%multiclass_roc_auc_score(y_test, y_pred))
```

#### Seaborn

Seaborn has great visualization and you should consider exploring more of the functionallity in their public API. https://seaborn.pydata.org/

You can create impressive visualizations such as 

![../_images/hexbin_marginals.png](../image/hexbin_marginals.png)



#### 