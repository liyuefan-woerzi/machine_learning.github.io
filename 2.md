# CS82 Introduction to Machine Learning
## Week 2 - Data Processing

### Libraries for Data

#### Numpy

Numpy is a library in python that helps working with arrays very easy. We import a library in python in the following way

```python
import numpy
```

we can use numpy functions then to generate a numpy array contain a range of 0 to 999 in the following way

```python
numpy.arange(1000)
```

Because typing numpy every time can be tiring and we are lazy programmers in python we can reduce the library name in the following way

```python
import numpy as np
```

the above then is the same

```python
np.arange(1000)
```

If we already had an list and we wanted to convert it to a numpy array we would do

```python
b=np.array([0,0,1]) # from example before

```

If we want to divide all elements in a numpy array **only** we can do the following:

```
print(b/5)
```

numpy tables, creates a numpy table with 0s of 3x4 dimensions  

`np.zeros( (3,4) )`

Reshaping 1d array to 2d and 3d

![Image result for reshaping numpy visualize](../image/example-of-using-numpy-reshape.png)

```
print(np.arange(12).reshape(4,3)) # must be multiple, 12 multiple of 4 and 3
print(np.arange(27).reshape(3,3,3))  # must be multiple, 27 multiple of 4 and 3
print(np.arange(24).reshape(4,3,2)) # must be multiple, 24 multiple of 4  3  and 2
```

Power of 2 and 3

```
print(np.arange(10)**3)
print(np.arange(10)**2)
```

Make a copy of a numpy array

```
a=np.arange(10)
b=a.copy()
b[1]=0
print(b)
print(a)
```

Compare to

```
a=np.arange(10)
b=a
b[1]=0
print(b)
print(a)

```

Selecting index ranges

```
print(a[2:5])
```

#### Pandas

Pandas is a library that similarly to numpy is helpful in managing data. The data is stored in what are called dataframes. The main advantage of Pandas over numpy are the powerful visualization tools it comes with, as well as the more intuitive approach at indexing (navigating) data as an example we can use named columns.

Reading a dataset with Pandas is easy from a given url  (make sure that the url contains a CSV dataset or use appropriate function for the format of the dataset instead of `read_csv`)

```
import pandas as pd
df=pd.read_csv("https://gist.githubusercontent.com/netj/8836201/raw/6f9306ad21398ea43cba4f7d537619d0e07d5ae3/iris.csv")
df[:3] # Prints first 3 rows
```

Displaying column, in **seperate** cells you can run

```
df['sepal.length']
```

![image-20190717151654256](../image/image-20190717151654256.png)

The left side is the index and the right side is the value of the column `sepal.length`

We can select a specific index range similar to how we would work with lists.

```
df['sepal.width'][:3]
```

![image-20190717151813261](../image/image-20190717151813261.png)

We can select multiple columns by passing them as a list to the dataframe 

```
df[['petal.length', 'sepal.width']] 
```

![image-20190717151909529](../image/image-20190717151909529.png)

Similarly

```

df[['sepal.width', 'petal.length']][:3] # order we select the columns is the display order

```

![image-20190717151933327](../image/image-20190717151933327.png)

We can execute specific functions on a column or an entire data frame as an example, value counts measures the frequency of each value

```

df['sepal.width'].value_counts()

```

![image-20190717152029270](../image/image-20190717152029270.png)

Or we can examine the unique values in a column (this return an array object)

```
df['sepal.width'].unique()

```

![image-20190717152108713](../image/image-20190717152108713.png)

In case we have missing values in a dataframe we can use fillna function. na, or nan, or NaN stands for `NULL` or `None` in python.

```

df.fillna(0) # replaces missing values with 0

```

The above function returns a **NEW** dataframe that is modified. Some functions in Pandas need to be run with an argument called `inplace`, this argument specifies that instead of returning a new object it will modify the existing object in memory. Example

```
df.fillna(0,inplace=True)
```

This should return nothing.

We can also obtain all rows in our dataframe that meet specific conditions (`numpy.nan` in this case specifies `NaN` or empty values. Our dataset is complete and hence not a good example for using this condition but datasets in the *wild* will definetely have missing values)

```

df[df['sepal.width'] == numpy.nan]

```

![image-20190717152538066](../image/image-20190717152538066.png)



```

df[df['sepal.width'] > 2]

```

![image-20190717152601327](../image/image-20190717152601327.png)

Or more complex conditions

```
df[(df['sepal.width'] > 2) & (df['sepal.length'] > 2)]
```

![image-20190717152723569](../image/image-20190717152723569.png)

Please note how the `&` symbol is used instead of the pythonic `and` this is because this is a special conditional statement, all conditions must be in paranthesis `()` and with spaces between the statements as shown above. The `OR` logic is defined as `|`

**These conditions are helpful in changing specific values of a dataframe**, we can assign values to a dataframe that meets these conditions or to an entire column following the syntax below

```
df[(df['sepal.width'] > 0) & (df['sepal.length'] > 0)]=1
df
```

![image-20190717160359158](../image/image-20190717160359158.png)



To plot a column we can use .plot() function

We use `%matplotlib inline` to let Jupyter know that it can plot in our browser window instead of simply saving it to memory

```
%matplotlib inline
df=pd.read_csv("https://gist.githubusercontent.com/netj/8836201/raw/6f9306ad21398ea43cba4f7d537619d0e07d5ae3/iris.csv")
df['sepal.width'].plot()
```

![image-20190717153131018](../image/image-20190717153131018.png)

### Plotting

Matplot Lib is a library that has many useful functions in creating plots. Plots can help us understand the data, discover trends as well as present our results in a structured manner. 

**Line Plot**

```
import matplotlib.pyplot as plt
import numpy as np
%matplotlib inline

plt.plot(np.arange(100))


```

![image-20190717155201196](../image/image-20190717155201196.png)



**Bar Plot**

```
import matplotlib.pyplot as plt
%matplotlib inline

names = ['group_a', 'group_b', 'group_c']
values = [1, 10, 100]
plt.bar(names, values)
```

![image-20190717155259597](../image/image-20190717155259597.png)



Scatter

```
import matplotlib.pyplot as plt
%matplotlib inline

names = ['group_a', 'group_b', 'group_c']
values = [1, 10, 100]
plt.scatter(names, values)
```

![image-20190717155353036](../image/image-20190717155353036.png)



**Subplots**

```
import matplotlib.pyplot as plt
%matplotlib inline

names = ['group_a', 'group_b', 'group_c']
values = [1, 10, 100]

plt.figure(1, figsize=(9, 3))

plt.subplot(131)
plt.bar(names, values)
plt.subplot(132)
plt.scatter(names, values)
plt.subplot(133)
plt.plot(names, values)
plt.suptitle('Categorical Plotting')
plt.show()

```

![](https://i.imgur.com/9dMV2E1.png)

#### Visualizing Iris sepal width and sepal length

```
df=pd.read_csv("https://gist.githubusercontent.com/netj/8836201/raw/6f9306ad21398ea43cba4f7d537619d0e07d5ae3/iris.csv")
df['variety'].unique() # get the unique values of iris varieties
```

![image-20190717161021200](../image/image-20190717161021200.png)

in a **single cell** (this behavior is because the plots are overlapping over another, otherwise you need much more complex logic to combine the plots together)

```python
plt.scatter(df[df['variety']=='Setosa']['sepal.length'], df[df['variety']=='Setosa']['sepal.width'], c='b')
plt.scatter(df[df['variety']=='Virginica']['sepal.length'], df[df['variety']=='Virginica']['sepal.width'], c='r')
plt.scatter(df[df['variety']=='Versicolor']['sepal.length'], df[df['variety']=='Versicolor']['sepal.width'], c='g')
```

![image-20190717161118473](../image/image-20190717161118473.png)

We can clearly see how the characteristics of an iris correspond to its type.

### Finding Datasets

During this course we will be working a lot with data. Machine Learning requries vast amounts of data to be effective. Knowing how to download, manipulate data is very important. The most important factor is also finding the right dataset for the right problem.

If we want to classify a tumor as benign vs malignant, the stock market data for such a problem would be useless. MRI scans in this case will be the most useful while X-Rays might not provide adequate information.

Understanding the problem is important in finding the right data for it. We can then search for public medical records or other resources.

Here is a list of websites that have datasets that can be useful:

* https://archive.ics.uci.edu/ml/datasets.html
* https://www.kaggle.com/datasets
* https://toolbox.google.com/datasetsearch
* https://data.gov

**How to Download a Dataset [UCI.edu](https://archive.ics.uci.edu/ml/index.php)**

Each website follows a different structure in downloading and handling data. It is something you should familiarize yourself with and is most of the times intuitive. 

Assume we want to work on the breast cancer problem of identifying a tumor as benign vs malignant. There is an existing dataset on tumors that can be found at 

https://archive.ics.uci.edu/ml/datasets/Breast+Cancer

To download that specific dataset we can visit the `Download Folder` link
![](https://i.imgur.com/u7DpCLc.png)

We see three files in the page. We don't always know which is the dataset we plan to use but by looking through all files it will be easy to identify apart from the .data extension.
![](https://i.imgur.com/EceDOL2.png)

Usually datasets have an extension: `csv` ,`json`,`data`,`xls`

Opening the breast-cancer.data file we can see that it is structured like a dataset we can use.

```
no-recurrence-events,30-39,premeno,30-34,0-2,no,3,left,left_low,no
no-recurrence-events,40-49,premeno,20-24,0-2,no,2,right,right_up,no
no-recurrence-events,40-49,premeno,20-24,0-2,no,2,left,left_low,no
no-recurrence-events,60-69,ge40,15-19,0-2,no,2,right,left_up,no
no-recurrence-events,40-49,premeno,0-4,0-2,no,2,right,right_low,no
no-recurrence-events,60-69,ge40,15-19,0-2,no,2,left,left_low,no
no-recurrence-events,50-59,premeno,25-29,0-2,no,2,left,left_low,no
no-recurrence-events,60-69,ge40,20-24,0-2,no,1,left,left_low,no
```

Most datasets would have multiple columns (sometimes comma seperated), and multiple rows. Some datasets can be images or text files and they might follow a different format. In those cases it is best to read the description on their webpage.

**Columns** on a dataset describe attributes of that dataset. For example in this dataset the second column is the age of the patient.

**Rows** in a dataset are the data points we use to train that dataset. Each datapoint has many attributes (see columns). For most machine learning problems we try to predict one attribute.

Additional information about the dataset is provided with the dataset and we can usually find it in the same place as our data, same file or website. For this dataset the information was in `breast-cancer.names`

```
Citation Request:
   This breast cancer domain was obtained from the University Medical Centre,
   Institute of Oncology, Ljubljana, Yugoslavia.  Thanks go to M. Zwitter and 
   M. Soklic for providing the data.  Please include this citation if you plan
   to use this database.

1. Title: Breast cancer data (Michalski has used this)

2. Sources: 
   -- Matjaz Zwitter & Milan Soklic (physicians)
      Institute of Oncology 
      University Medical Center
      Ljubljana, Yugoslavia
   -- Donors: Ming Tan and Jeff Schlimmer (Jeffrey.Schlimmer@a.gp.cs.cmu.edu)
   -- Date: 11 July 1988

.
.
.


7. Attribute Information:
   1. Class: no-recurrence-events, recurrence-events
   2. age: 10-19, 20-29, 30-39, 40-49, 50-59, 60-69, 70-79, 80-89, 90-99.
   3. menopause: lt40, ge40, premeno.
   4. tumor-size: 0-4, 5-9, 10-14, 15-19, 20-24, 25-29, 30-34, 35-39, 40-44,
                  45-49, 50-54, 55-59.
   5. inv-nodes: 0-2, 3-5, 6-8, 9-11, 12-14, 15-17, 18-20, 21-23, 24-26,
                 27-29, 30-32, 33-35, 36-39.
   6. node-caps: yes, no.
   7. deg-malig: 1, 2, 3.
   8. breast: left, right.
   9. breast-quad: left-up, left-low, right-up,	right-low, central.
  10. irradiat:	yes, no.
```

In this description of this specific dataset we can see information relating to the possible values we have for each **attribute**. This can be useful when we learn how to properly convert this data into a Machine Learning problem to solve.

### Downloading a Dataset

Your browser should automatically download a dataset if it is of the right format. In this case the browser fails to prompt you for the download window. To Download a Dataset we can `Right Click` on the link that points to the dataset and then `Save Link Asâ€¦`

![image-20190718105639040](../image/image-20190718105639040.png)

**OR**

You can directly `Copy Link Location` and pass it into `pandas.read_csv("link_here")` or the correct pandas function for the correct type of dataset.

#### Searching for a Dataset

Sometimes we can search for interesting datasets or find one that can help us solve a specific problem. We will go over how to search a dataset in the websites listed above.

#### [Kaggle](http://kaggle.com)
Kaggle has trending datasets that are updating every few hours/days. You can draw inspiration for a problem to solve from there.

![](https://i.imgur.com/pLNiNwI.png)


Let's take a look at the **Graduate Admissions** dataset

![](https://i.imgur.com/fDqmuFj.png)

We can see the columns, of the data
```
Serial No.
GRE Score
TOEFL Score
University Rating
SOP
LOR
CGPA
Research
Chance of Admit
```

To Download the dataset we have to click the hard to find button:
![](https://i.imgur.com/NOZ0gZJ.png)



**Button Zoomed in**

![](https://i.imgur.com/buMcha0.png)



At this point you might be asked to create an account and the easiest thing would be to log in with your Google Account or Register for a new account.
![](https://i.imgur.com/UgqkUZz.png)

#### [Google Datasets](https://toolbox.google.com/datasetsearch)

In a similar way we can use Google and we can search the internet for interesting datasets.

![](https://i.imgur.com/9ViN31l.png)


The results are on the left side

![image-20190718105930304](../image/image-20190718105930304.png)


Some results are also from Kaggle or other goverment websites such as ornl.gov and data.gov.

We can click on a dataset for more details like

![](https://i.imgur.com/SW1UN5o.png)

#### Details

![](https://i.imgur.com/XlRbSUM.png)


Each of the links in the dataset can lead to a source. Sometimes there are descriptions provided and additional informations such as number of citations.

Downloading a dataset from Google can be challenging since each website has a different format but most of them follow similar patterns as above. You can try different and multiple links for the same dataset to find a website that is easy to navigate.

### [data.gov](http://data.gov)

Data.gov contains datasets published by the government. It is an excellent source for finding a dataset to solve a problem that can have a large social impact.

After visiting [Data.gov](data.gov) we can see multiple categories for datasets.



![](https://i.imgur.com/2ZApUGY.png)



We can explore datasets based on our interest or problem we are trying to solve.



![](https://i.imgur.com/WtJ3cXz.png)



After selecting a category we can see available datasets by clicking the data tab.



![](https://i.imgur.com/v96k6aN.png)



This is what the results might look like.

Formats of XLS and CSV are the easiest to work with.



![](https://i.imgur.com/XGuEli1.png)



We can check if the link is valid **Link is ok** and then we can download it.



We can click download or copy the download link by hitting right click and download. We will see how we can import such a dataset in our program in a bit.

`https://openei.org/doe-opendata/dataset/a7fea769-691d-4536-8ed3-471e993a2445/resource/86c50aa8-e40f-4859-b52e-29bb10166456/download/populationbycountry19802010millions.csv`


Many times we will get to missing or broken pages. There is little we can do about it. If the dataset is really important to our project we can use google to find alternative host locations.

### Working with Data

After we identified a dataset we want to work with, we have to make sure it is in the right format for us to work with.

Depending on what our dataset is, it can have different formats. Most common is that the dataset will have multiple columns with attributes. Example of such a dataset is the population by country from 1980 to 2010 in millions. 

`https://openei.org/doe-opendata/dataset/a7fea769-691d-4536-8ed3-471e993a2445/resource/86c50aa8-e40f-4859-b52e-29bb10166456/download/populationbycountry19802010millions.csv`

#### Downloading

To download the dataset we can either download it from the command line and import it as a file, directly import it as a url or download it from the notebook.
#### Executing Terminal Commands in Jupyter

You can execute the exactly same commands in a Jupyter cell as in a terminal. To do that you need to start by using `!` symbol. For example wget, a command we looked at **Handout 1** can be executed as 

`!wget url`

#### Download a dataset from terminal

`wget https://openei.org/doe-opendata/dataset/a7fea769-691d-4536-8ed3-471e993a2445/resource/86c50aa8-e40f-4859-b52e-29bb10166456/download/populationbycountry19802010millions.csv`

![image-20190717171445959](../image/image-20190717171445959.png)

Please notice the output of the command

`Saving to` is the name of the file we have downloaded

if we list the files we will see it among them. Since I have run the command twice, a number 1 is added to the end of the file.

![image-20190717171550592](../image/image-20190717171550592.png)

#### Download a dataset from jupiter

`!wget https://openei.org/doe-opendata/dataset/a7fea769-691d-4536-8ed3-471e993a2445/resource/86c50aa8-e40f-4859-b52e-29bb10166456/download/populationbycountry19802010millions.csv`
![](https://i.imgur.com/ExdgVzO.png)
Name of the dataset is `populationbycountry19802010millions.csv`

#### Importing a Dataset

To import our dataset, we can either do that from the file, in case we modify it this is a useful thing to do. Or we can read it directly from the URL. 

#### Importing a URL dataset

```
import pandas as pd
pd.read_csv("https://openei.org/doe-opendata/dataset/a7fea769-691d-4536-8ed3-471e993a2445/resource/86c50aa8-e40f-4859-b52e-29bb10166456/download/populationbycountry19802010millions.csv")
```

#### Importing a File dataset

```
import pandas as pd
pd.read_csv("populationbycountry19802010millions.csv")
```
![](https://i.imgur.com/Iu8RgLM.png)
#### List of available pandas formats
![](https://i.imgur.com/2tZtKdJ.png)

#### Processing Datasets line by line

In case our dataset is in bad format or some error is caused while opening it, we can read the dataset line by line as the example below.

```python
!wget https://openei.org/doe-opendata/dataset/a7fea769-691d-4536-8ed3-471e993a2445/resource/86c50aa8-e40f-4859-b52e-29bb10166456/download/populationbycountry19802010millions.csv

f = open("populationbycountry19802010millions.csv", "r")
content=f.read()
data=[]
for line in content.split("\n"):
  row=line.split(",")
  data.append(row)
df=pd.DataFrame(data)
df
```
![](https://i.imgur.com/LXTLyTQ.png)



### Datasets

Anything can be data, this handout is a data-point. We call data-points, **instances** of a dataset. Each **instance** has **attributes**.

In our case the attributes is the Country, and Population at year X. Attributes usually are the columns of the dataset.

Many times attributes can be images, or file paths to images, text. In this case we treat it the same as the attributes we have on this file.

![](https://i.imgur.com/BajaWUx.png)

The numbers on the left are the **indexes**, and index can be a number, string or year. **index is unique**.

We address the index using

`df.loc[<INDEX RANGE> , <COLUMNS RANGE>]`

`df.loc[<INDEX RANGE>]`

We can address alternatively only the columns using

`df[<COLUMNS RANGE>]`



```
df.loc[1,0]
```

![image-20190717172420179](../image/image-20190717172420179.png)

```
df.loc[0]
```

![image-20190717172457376](../image/image-20190717172457376.png)

```
df.loc[0,:]
```

![image-20190717172640467](../image/image-20190717172640467.png)



To correct the wrong header, we can set the `df.columns` as the first row, and then `drop` the first row of our dataset. Remember to do this `inplace`. We also set the index as the column ` ' '` which is an empty character because of how our data was read, the index column had no name.

```
df.columns=df.loc[0]
df.drop(0,inplace=True)
# empty string because the column value is empty
df.set_index('')
```

![](https://i.imgur.com/hQ0cnFN.png)
### Inplace <span style='color:red'>Warning</span>

If you don't use the inplace parameter, the changes are not saved
![](https://i.imgur.com/6mQLTIN.png)

Either do

```
df.set_index('',inplace=True)
```
**OR**
```
df=df.set_index('')
```

We can now index by Country name:

```python
df.drop('Canada') # Not in place, not saved
```

```python
df.loc['Canada'] # This will cause an error if the above was done in place. Let's get an array of all Canada values over time
```
![image-20190717173122824](../image/image-20190717173122824.png)

### Data Type <span style='color:red'>Warning</span>

**<span style='color:red'>Error</span>**

```
df.loc['Canada'].mean()
```
> TypeError: must be str, not int

Converting the datatype to float

```
df.loc['Canada'].astype(float).mean()
```
> 29.339819677419353
**<span style='color:red'>Still an Error</span>**

```
df.loc['Canada'].mean()
```
> TypeError: must be str, not int

**Don't forget to assign the results back to the dataframe or do it inplace** 

```
df.loc['Canada']=df.loc['Canada'].astype(float)
```
**Pointers <span style='color:red'>Warning</span>**

Pointers are references to the same memory space under different variable names. Think about it that both variables will point to exact same value but we can use different names to modify that value or retreive it. That means that changing the value of one variable automatically changes the value of another variable. We can see this can cause some very confusing behavior. Consider the example below. 

```python
dfx=df
dfx.loc['Canada']="ktbyte" # Change the value of population for the country of Canada for the dfx variable
df # display the initial dataframe that should have remained unchanged
```



![](https://i.imgur.com/qPaziKT.png)

**Alternatively** 

We need to use the function `copy()`. That function will make a new copy in memory and assign it to the new variable names. Changes to the new variable will not overlap with the old variable.

To copy a dataframe (and not just use a new name for it)

```
dfx=df.copy()
dfx.loc['Canada']="ktbyte"
print(df['Canada'])
print(dfx['Canada'])
```

#### Useful DataFrame Functions

* df.describe()
* df.head()
* df.tail()
* df.loc['index'].values
* df['column'].values
* np.unique(df['column'].values)
* np.unique(df.loc['column'].values, return_counts=True)
* df.apply(function)
* df.fillna("value")

As an example, we are going to use a function from pandas that converts each number to a numeric value, so that we can vizualize it. This function is called `to_numeric`, we are going to apply it to the dataframe using the `apply` function. In case of errors, we specify to leave them as `NaN`. We then `fillna(0)` which replaces all erronous values with 0. We will discuss more strategies for erronous or missing values in the future.

```
df=df.apply(pd.to_numeric, errors='coerce').fillna(0) 
```
### Visualization
```

f = open("populationbycountry19802010millions.csv", "r")
content=f.read()
data=[]
for line in content.split("\n"):
    row=line.split(",")
    data.append(row)
df=pd.DataFrame(data)
df.columns=df.loc[0]
df.drop(0,inplace=True)
df.set_index('',inplace=True)

us_pop=df.loc['United States'].reset_index()
us_pop.columns=['Year','Population in Millions']
us_pop=us_pop.apply(pd.to_numeric, errors='coerce')
us_pop.dropna(inplace=True)
us_pop.plot(x="Year",y="Population in Millions")

```

![image-20190717181121442](../image/image-20190717181121442.png)

For larger plots we can execute the following code (that makes our figures 20x10)

```
import matplotlib.pyplot as plt
from pylab import rcParams
rcParams['figure.figsize'] = 20,10
us_pop.plot(x="Year",y="Population in Millions")
```
![image-20190717181256750](../image/image-20190717181256750.png)
```
numeric_df=df.apply(pd.to_numeric, errors='coerce')
numeric_df.mean(axis=1).plot.bar()
```
![](https://i.imgur.com/XkhZzfZ.png)

```
numeric_df.mean(axis=1).sort_values().plot.bar()
```
![](https://i.imgur.com/Fr5iDCm.png)
